# ğŸš€ğŸŒŸ ModelMancer âœ¨ğŸ¤–

A sleek AI-powered model recommendation assistant based on your device's RAM ğŸ’¡  
Live app: ğŸ‘‰ [https://modelmate-xi.vercel.app/](https://modelmate-xi.vercel.app/)

---

## ğŸ”§ Getting Started

You can easily edit the app in your favorite development environment.

### ğŸ› ï¸ Local Setup

> âš ï¸ Requires Node.js & npm.  
> Recommended: Install via [nvm](https://github.com/nvm-sh/nvm#installing-and-updating)

```bash
# 1. Clone the repository
git clone <YOUR_GIT_URL>

# 2. Navigate to the project directory
cd <YOUR_PROJECT_NAME>

# 3. Install dependencies
npm install

# 4. Run the app locally
npm run dev
```

ğŸŒ Visit: [http://localhost:5173](http://localhost:5173)

---

## ğŸ§  Features at a Glance

âœ… **RAM-based model suggestions** using structured CSV/Excel data  
âœ… **Ollama-powered AI assistant** with interactive chat  
âœ… **Voice input + translation** for multilingual interaction  
âœ… **Multilingual UI:** English, à¤¹à¤¿à¤‚à¤¦à¥€, à°¤à±†à°²à±à°—à±  
âœ… **Runs on Vercel** for instant access

---

## ğŸŒ Multilingual Support

| Language | Code |
|----------|------|
| ğŸ‡¬ğŸ‡§ English | `en` |
| ğŸ‡®ğŸ‡³ Hindi   | `hi` |
| ğŸ‡®ğŸ‡³ Telugu  | `te` |

ğŸ›  Add more languages via `i18n.ts`

---

## ğŸ—‚ï¸ Project Structure

```
llm-whisper-advisor-pilot/
â”œâ”€â”€ public/               # Static assets (icons, images)
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ components/       # UI components (chat UI, buttons)
â”‚   â”œâ”€â”€ contexts/         # Language and theme context
â”‚   â”œâ”€â”€ data/             # Model data (CSV/Excel)
â”‚   â”œâ”€â”€ pages/            # Page-level views
â”‚   â””â”€â”€ utils/            # Utility functions
â”œâ”€â”€ package.json          # Dependencies
â”œâ”€â”€ vite.config.ts        # Vite config
â””â”€â”€ tailwind.config.ts    # Tailwind theme
```

---

## ğŸ¤– Supported Models

âœ¨ Includes support for top open-source LLMs:

- ğŸ§  LLaMA 2 & 3 (Meta)
- âš¡ Mistral 7B / Mixtral
- ğŸ” Google Gemma
- ğŸ“˜ Phi-2 / Phi-3 (Microsoft)
- ğŸ§™ WizardLM, Zephyr, Dolphin
- ğŸ’» CodeLlama / DeepSeek-Coder
- ğŸ”¢ Quantized 70B models (8-bit)

> All models are mapped against RAM profiles (ultra low â†’ ultra high)

---

## ğŸ“¦ NPM Scripts

```bash
npm run dev        # Start dev server
npm run build      # Build for production
npm run preview    # Preview production
npm run lint       # Lint with ESLint
```

---

## ğŸ¤ Contributing

Contributions are welcome!

- ğŸ”§ Fork the repo
- ğŸ“¥ Submit a pull request
- ğŸ› Open issues for bugs/features

> Please open an issue first for large changes.

---

ğŸ’¡ *Built with â¤ï¸ using Vite + React + Tailwind + Ollama*
